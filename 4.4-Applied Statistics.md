In this course, I mainly learned descriptive statistical analysis, hypothesis testing, analysis of variance (ANOVA), and regression analysis. 

This was a lab-based course focused on using Minitab, a statistical software, to process and analyze real-world data, helping us discover patterns, test ideas, and make more data-driven decisions. **It wasn’t just about theory—we spent a lot of time doing hands-on work**, such as entering data, running analyses, and interpreting output. 

**The whole process was like a chef using kitchen tools: Minitab was our “toolkit,” and the statistical methods were the “recipes.” We had to learn how to use the right recipe to make the right dish—in other words, to draw meaningful conclusions from data.**

## Descriptive Statistical Analysis

Descriptive statistical analysis is the foundation of this course. It’s about how to summarize and present the characteristics of data in a simple and intuitive way. 

For example, suppose there are 30 students in my class, each with a different final exam score. How can we quickly understand the overall performance? We wouldn’t look at each score one by one. Instead, we’d calculate measures like the mean, median, and standard deviation. The mean tells us the average level, the median shows the middle value (less affected by extremely high or low scores), and the standard deviation tells us how spread out the scores are—if it’s small, scores are similar; if it’s large, there’s a wide gap between high and low performers. In Minitab, after importing the score data, we can click on “Basic Statistics” to instantly get these numbers. We also learned to visualize data using histograms and boxplots. A histogram is like dividing scores into “bins,” where the height of each bin shows how many people scored in that range—this lets us quickly see if most scores are high or low. For instance, we once analyzed the lengths of parts from a factory. The average was 10.2 cm with a standard deviation of 0.3 cm. The histogram showed a bell-shaped curve, indicating stable production.

## Hypothesis Testing

Next is hypothesis testing, which is about using data to check whether a guess or claim is supported. 

For example, suppose we suspect a new teaching method improves students’ exam scores. We can’t just say “it seems better”—we need data to prove it. We designed an experiment: randomly dividing students into two groups—one taught with the traditional method (control group), the other with the new method (experimental group)—then comparing their average scores. Here, we used a “two-sample t-test.” In Minitab, we input the scores from both groups, select “two-sample t-test,” and the software automatically calculates a p-value. The p-value acts like a measure of “strength of evidence.” If the p-value is less than 0.05 (a common threshold), we conclude there’s enough evidence to reject the null hypothesis (that the new method has no effect), meaning the new method likely works. In one case, the control group averaged 75, the experimental group 82, and the p-value was 0.02—less than 0.05. So we concluded the new teaching method significantly improved scores. This is like a court trial: the null hypothesis is “the defendant is innocent,” and a small p-value is like strong evidence leading to a guilty verdict.

## Analysis of Variance

Analysis of variance (ANOVA) is an extension of hypothesis testing, used to compare whether the means of three or more groups are significantly different. 

For example, suppose we want to compare the impact of three different ad designs on product sales. We randomly assign customers to three groups, each seeing one ad, and record their purchase amounts. If we used t-tests, we’d need three pairwise comparisons, which increases the chance of error. ANOVA allows us to compare all groups at once. In Minitab, we input the three datasets, select “One-Way ANOVA,” and the software outputs an F-value and a p-value. If the p-value is less than 0.05, it means there’s a significant difference between at least two groups. We can then use “multiple comparisons” (like Tukey’s test) to identify exactly which pairs differ. In a real case, the average sales for the three ads were 220 yuan, 250 yuan, and 210 yuan. The ANOVA p-value was 0.01, indicating ad design significantly affects sales. Further comparison showed the second ad performed significantly better than the other two. This is like comparing three people’s heights—not measuring each pair separately, but using one method to judge if they’re all the same.

## Regression Analysis

Finally, regression analysis is about studying how one variable changes as one or more other variables change. 

For example, we want to know the relationship between advertising spending and sales. We collected data from the past 12 months: monthly ad spending and corresponding sales. In Minitab, we ran a “simple linear regression,” plotted a scatterplot, and the software automatically fitted a line, such as “Sales = 50,000 + 8 × Ad Spending.” This equation means: even with zero ad spending, we expect 50,000 in sales; for every additional yuan spent on ads, sales increase by 8 yuan on average. The slope, 8, is the “regression coefficient,” showing the marginal effect of advertising. We also look at the R-squared value—say, 0.85—which means ad spending explains 85% of the variation in sales, indicating a good model fit. We also did multiple regression, adding variables like “promotions” and “season,” and found promotions had an even bigger impact than ads. Regression is like weather forecasting—we use multiple factors like pressure, humidity, and wind speed to predict if it will rain tomorrow.