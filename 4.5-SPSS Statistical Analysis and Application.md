In this course, I mainly learned descriptive statistical analysis, correlation analysis, regression analysis, and factor analysis. 

This course is a hands-on experimental class, and its main goal is to teach us how to use SPSS, a statistical software, to process and analyze data from real research, so we can discover patterns and test hypotheses from data. The course doesn’t focus much on abstract math formulas, but emphasizes "how to do it"—for example, how to enter survey data into a computer, how to clean up incorrect data, how to present results with charts, how to tell if two variables are related, and how to build a simple prediction model. Every class was held in a computer lab where we followed the teacher step by step using SPSS, and our homework was based on real small-scale survey datasets.

## Descriptive Statistical Analysis

Descriptive statistical analysis is the most basic and important part of this course. Simply put, it uses simple numbers and charts to “describe” the basic features of a group of data. 

For example, our class conducted a small survey collecting data on how many hours 50 students spend studying each week. The raw data might be messy numbers—some study 5 hours, others 30. Descriptive statistics helps us quickly understand the overall picture: the mean tells us the average weekly study time, say 15 hours; the standard deviation tells us how “spread out” the data is—if it’s small, most people are close to 15 hours; if it’s large, some study very little and others a lot. We also look at minimum, maximum, and median values. In SPSS, with just a few clicks in the menu, we can generate these statistics and create histograms or boxplots to visually see the data distribution. It’s like taking a “group photo” of the data, so we can instantly see the overall trend and spot any unusual outliers.

## Correlation Analysis

Next is correlation analysis, which is used to determine whether there is an association between two variables. 

For example, we want to know if there’s a relationship between “study time” and “final exam scores.” In SPSS, we use the Pearson correlation coefficient to measure this relationship, which ranges from -1 to +1. If the result is +0.65, it means that longer study time tends to be associated with higher scores—a positive correlation. If it’s -0.4, it means as one variable increases, the other tends to decrease—like “gaming time” and “scores,” which might be negatively correlated. But it’s important to note that correlation does not imply causation—it only tells us that two things change together, not that one causes the other. In SPSS, we select the two columns of data, run the correlation analysis, and the software outputs a correlation coefficient and a p-value. If the p-value is less than 0.05, we consider the correlation statistically significant, meaning it’s unlikely to have occurred by chance. For example, our class data showed a correlation coefficient of 0.68 between study time and scores, with a p-value of 0.001, indicating a real positive relationship.

## Regression Analysis

Regression analysis is the part I found most useful in this course because it not only discovers relationships but can also be used for prediction. For example, if a student studies 20 hours per week, what might their score be? That’s where linear regression comes in. In SPSS, we set “score” as the dependent variable—the outcome we want to predict—and “study time” as the independent variable—the factor we use to predict. The software calculates a regression equation for us, like “Score = 50 + 2.5 × Study Time.” This means that even with zero study, the baseline score might be 50, and each additional hour of study increases the score by an average of 2.5 points. This equation is calculated using the least squares method, which minimizes the difference between predicted and actual values. We also look at the R-squared value—say, 0.46—which means study time explains 46% of the variation in scores; the remaining 54% may be due to other factors like study methods or prior knowledge. Regression analysis is widely used in management research, such as predicting sales or customer satisfaction.

## Factor Analysis

Finally, factor analysis is a slightly more complex but very interesting method used when dealing with many variables. For example, we designed a survey on “learning satisfaction” with 20 questions like “Is the teacher’s explanation clear?”, “Is the course content interesting?”, “Is the workload reasonable?”, etc. These questions might actually be measuring a few underlying “factors,” such as “teaching quality” and “course workload.” Factor analysis helps us “condense” these 20 questions into a few meaningful dimensions. In SPSS, we first run the KMO and Bartlett’s test to check if the data is suitable for factor analysis—if the KMO value is above 0.6, we can proceed. Then we use Principal Component Analysis to extract factors and apply rotation (like Varimax rotation) to make the factors easier to interpret. Eventually, we might end up with 4 factors, such as “teaching quality,” “course content,” “assessment method,” and “study pressure,” each composed of several original questions. This way, we can use these 4 newly created factor variables for further analysis like regression, greatly simplifying the research process.